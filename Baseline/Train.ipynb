{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from preprocessing_labels import training_data,validation_data,idx_to_name,idx_to_umls,umls_to_idx\n",
    "\n",
    "from preprocessing_images import Data,preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    dataset_sizes = {'train': len(dataloaders['train'].dataset), \n",
    "                     'valid': len(dataloaders['valid'].dataset)}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                #breakpoint()\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            batch_count=0;\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                \n",
    "                batch_count+=1;\n",
    "                #breakpoint()\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.float().cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels.float())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "                #breakpoint()\n",
    "                print('epoch: ' +str(epoch+1)+'/'+str(num_epochs)+'    batch: ' + \n",
    "                      str(batch_count)+'/'+str(dataloaders[phase].__len__())+\n",
    "                      '\\t Loss: ' + str(loss.detach().item()));      \n",
    "                \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                \n",
    "\n",
    "        print('Epoch [{}/{}] train loss: {:.4f} ' \n",
    "              'valid loss: {:.4f}'.format(\n",
    "                epoch+1, num_epochs,\n",
    "                train_epoch_loss, \n",
    "                valid_epoch_loss))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(model,net_name,directory,data):\n",
    "    '''saves and returns the outputs from the model after feeding in the dataset'''\n",
    "    \n",
    "    all_outputs=np.zeros((len(data),1000))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for t in range(len(all_outputs)):\n",
    "            \n",
    "            print(str(t)+'/'+str(len(data)))\n",
    "        \n",
    "            fullname = directory+idx_to_name[t]+'.jpg'\n",
    "    \n",
    "            image = Image.open(fullname).convert('RGB')\n",
    "    \n",
    "            image = preprocessing(image)\n",
    "            \n",
    "            image = Variable(image.cuda()).view((1,3,224,224))\n",
    "            \n",
    "            output=model(image.view(1,3,224,224))[0]\n",
    "            \n",
    "            output_np=output.cpu().detach().numpy()\n",
    "            \n",
    "            #indices_threshold=np.argwhere(output_np>threshold)\n",
    "            \n",
    "            all_outputs[t]=output_np\n",
    "            \n",
    "    np.save('models/'+net_name+'_all_outputs',all_outputs)\n",
    "    \n",
    "    return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_files(thresholds, max_per_sample,net_name,array_of_outputs):\n",
    "    '''creates the formatted submission text files for each threshold\n",
    "    thresholds: list of thresholds on the interval [0,1]\n",
    "    max_per_sample: the maximum amount of concepts allowed per sample\n",
    "    '''\n",
    "    \n",
    "    filenames=[net_name+'_t'+ str(thresholds[i])+'.txt' for i in range(len(thresholds))]\n",
    "    \n",
    "    over_100=[]\n",
    "    \n",
    "    for j,threshold in enumerate(thresholds):\n",
    "\n",
    "        array_of_outputs_sorted=-np.sort(-array_of_outputs,1)[:,:max_per_sample]\n",
    "        array_of_outputs_argsorted=np.argsort(-array_of_outputs,1)[:,:max_per_sample]\n",
    "        \n",
    "        binary=array_of_outputs_sorted>threshold\n",
    "        \n",
    "        f=open(filenames[j], 'w')\n",
    "        over_100_true=False\n",
    "        \n",
    "        for t in range(len(array_of_outputs)):\n",
    "            \n",
    "\n",
    "            \n",
    "            #indices_threshold=np.argwhere(array_of_outputs>threshold)\n",
    "            if t%500==0:\n",
    "                pass;#print('t is ' +str(t))\n",
    "            \n",
    "            indices=np.argwhere(binary[t]==1)\n",
    "            indices.shape=len(indices)\n",
    "            \n",
    "            if len(indices)>100:\n",
    "                over_100_true=True\n",
    "                over_100.append(t)\n",
    "            \n",
    "            line=idx_to_name[t]+'\\t'\n",
    "            for i in indices:\n",
    "                line+=idx_to_umls[array_of_outputs_argsorted[t,i]]+','\n",
    "                \n",
    "            line=line[:-1]\n",
    "            line+='\\n'\n",
    "            f.write(line)\n",
    "        f.close()\n",
    "        \n",
    "        if over_100_true==True:\n",
    "            print('there is at least one sample with over 100 UMLS codes')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path,resnet):\n",
    "    \n",
    "    if os.path.isfile(model_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "        checkpoint = torch.load(model_path)\n",
    "        resnet.load_state_dict(checkpoint['state_dict'])\n",
    "        resnet.load_state_dict(checkpoint['optimizer'])\n",
    "        \n",
    "        \n",
    "    \n",
    "        if use_gpu:\n",
    "            resnet = resnet.cuda()\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"=> loaded checkpoint '{}' \"\n",
    "                  .format(model_path))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(model_path))\n",
    "\n",
    "    return resnet\n",
    "\n",
    "\n",
    "def save_model(filename,net,save_path):\n",
    "\n",
    "    state = {'state_dict': net.state_dict(),\n",
    "             'optimizer': net.state_dict() }\n",
    "    torch.save(state, save_path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "training_path='training_path'\n",
    "validation_path='validation_path'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocessing = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds=Data(training_data,directory=training_path,transform=preprocessing)\n",
    "\n",
    "training_dl=DataLoader(training_ds,batch_size=64,shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "#validation_ds=Data(training_data, directory=validation_path,transform=preprocessing)\n",
    "\n",
    "validation_ds=Data(validation_data, directory=validation_path,transform=preprocessing)\n",
    "\n",
    "validation_dl=DataLoader(validation_ds,batch_size=32,shuffle=True, num_workers=0)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_new_class import resnet50\n",
    "resnet = resnet50(pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "    resnet = resnet.cuda()\n",
    "    #inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())   \n",
    "else:\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        #criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
    "        optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=.001, momentum=0.9)\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "            \n",
    "        dloaders = {'train':training_dl, 'valid':validation_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train_model(dloaders, resnet, criterion, optimizer, exp_lr_scheduler, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_name='model_1'\n",
    "save_path='save_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(net_name,model,save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds=[.3,.5,.75,.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs=get_outputs(model,net_name,training_path,training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_text_files(thresholds,25,net_name,all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_f1 import main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the main function takes in a candidate file, and the ground truth file. It compares the two and outputs the mean f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main(candidate_file.txt, ground_truth.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
